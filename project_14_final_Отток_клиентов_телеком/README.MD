**Краткое описание**: 
на основе данных телеком-компании определить, вероятность ухода клиента, чтобы предложить ему тарифные опции.

**Задачи**:
- пострить модель предсказания ухода клиента из телеком-компании;
- определеить значимые признаки для модели предсказания;
- достичь максимального значения метрики точности модели (`ROC-AUC`)

**Статус проекта**:
- завершен.

**Выполненные шаги**:
- просмотрена общая информация таблицы исходных данных, проверены уникальные значения, пропуски, 
количество `NaN` значений;
- выделены значимые для дальнейшего обучения моделей признаки, по которым произвели слияние таблиц;
- полученные значения `NaN` были заменены на `No`, означающие не подключенную услугу;
- создана *целевая таблица* с нужными признаками, было проверено три возможных из теоретического курса варианта обработки признаков: 
    - без обработки категориальных признаков;
    - обработка значений методом прямой кодировки без использования обхода дамми-ловушки;
    - обработка методом порядкового кодирования;
    - для числовых значений использована стандартизация больших значений.
- *целевая таблица* была выбрана с учетом низкой мультиколлинеарности;
- выделено две выборки:
    - тренировочная;
    - тестовая.
- проверено 5 моделей обучения без подбора гиперпараметров;
- были обучены те же модели при помощи метода кросс-валидизации;
- обученые модели были проверены на тестовой выборке;
- изучены значения AUC-ROC всех рассматриваемых моделей на тестовой выборке;
- все значения AUC-ROC были занесены в таблицы для удобства сравнения;
- отражены ROC-кривые для различных моделей, отработавших на тестовой выборке, 
на одном графике для удобства сравнения;
- для лучших моделей обучения были показаны значимые для обучения признаки;
- для лучшей модели были подобраны гиперпараметры и вновь обучена с учетом этих параметров.

**Выводы работы**: 
- на данных с порядковым кодированием категориальных признков:
       - наиболее высокая точность прогноза была представлена моделями `XGBClassifier`, `CatBoostClassifier`, которые достигли соответственно значениий  `0.901319`, `0.900846`;
       - наиболее значимыми для модели `XGBClassifier` оказались признаки `type`, `internetservice`, `lifetime`;
       - наиболее значимыми для модели `CatBoostClassifier` оказались признаки `lifetime`, `monthlycharges`,`type`.
- на данных с порядковым кодированием категориальных признков с кроссвалидизацией:
       - наиболее высокая точность прогноза была представлены моделями `CatBoostClassifier`, `XGBClassifier`, которые достигли соответственно значениий  `0.851154`, `0.831324`.
       - наиболее значимыми для модели `CatBoostClassifier` оказались признаки `lifetime`, `monthlycharges`,`type`;
       - наиболее значимыми для модели `XGBClassifier` оказались признаки `type`, `internetservice`, `lifetime`.
       
- для подборов гиперпараметров была выбрана модель `CatBoostClassifer` ввиду ее более быстрой работы, получены результаты:
  - лучшее значение метрики ROC-AUC - `0.87628899`;
  - лучшие гиперпараметры модели - `{'depth': 5, 'iterations': 30, 'verbose': False}`


**Используемый стэк**:
- `jupiter`
- `pandas`
- `numpy`
- `matplotlib`
- `xgboost` (`XGBClassifier`)
- `catboost` (`CatBoostClassifier`)
- `sklearn`:
  - `sklearn.preprocessing` (`StandardScaler`, `OrdinalEncoder`)
  - `sklearn.utils` (`shuffle`)
  - `sklearn.tree` (`DecisionTreeClassifier`)
  - `sklearn.ensemble` (`RandomForestClassifier`)
  - `sklearn.linear_model` (`LogisticRegression`)
  - `sklearn.model_selection` (`train_test_split`, `GridSearchCV`, `cross_val_score`)
  - `sklearn.dummy` (`DummyClassifier`)
  - `sklearn.metrics` (`roc_auc_score`, `roc_curve`, `precision_recall_curve`)
